{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "client = openai.OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = \"Note: If you are ever prompted to answer yes or no, only answer with yes or no, with no other text.\"\n",
    "\n",
    "def create_single_message_history(text: str):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": DEFAULT_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": f\"{text}\"}\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_text_and_logprobs_from_response(response):\n",
    "    text = response.choices[0].message.content\n",
    "    token_logprobs = {\n",
    "        x.token: x.logprob for x in response.choices[0].logprobs.content[0].top_logprobs\n",
    "    }\n",
    "    return text, token_logprobs \n",
    "\n",
    "\n",
    "def get_response_text_and_logprobs(messages: list[dict], model: str, **model_kwargs):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        logprobs=model_kwargs.pop(\"logprobs\", True),\n",
    "        top_logprobs=model_kwargs.pop(\"top_logprobs\", 10),\n",
    "        **model_kwargs\n",
    "    )\n",
    "    # check for errors\n",
    "    if response.choices[0].finish_reason != \"stop\":\n",
    "        raise ValueError(f\"Unexpected finish reason: {response.choices[0].finish_reason}\")\n",
    "    text = response.choices[0].message.content\n",
    "    token_logprobs = {\n",
    "        x.token: x.logprob for x in response.choices[0].logprobs.content[0].top_logprobs\n",
    "    }\n",
    "    return text, token_logprobs\n",
    "\n",
    "\n",
    "def calculate_yes_no_logprobs(token_logprobs: dict[str, float]):\n",
    "    yes_logprobs = []\n",
    "    no_logprobs = []\n",
    "    for token, logprob in token_logprobs.items():\n",
    "        if token.strip().lower() == \"yes\":\n",
    "            yes_logprobs.append(logprob)\n",
    "        elif token.strip().lower() == \"no\":\n",
    "            no_logprobs.append(logprob)\n",
    "    \n",
    "    yes_total = -np.inf if not yes_logprobs else np.logaddexp.reduce(yes_logprobs)\n",
    "    no_total = -np.inf if not no_logprobs else np.logaddexp.reduce(no_logprobs)\n",
    "    \n",
    "    return yes_total, no_total\n",
    "\n",
    "\n",
    "def append_to_csv(result: dict, out_csv: Path):\n",
    "    import csv\n",
    "    if not isinstance(out_csv, Path):\n",
    "        out_csv = Path(out_csv)\n",
    "    if not out_csv.exists():\n",
    "        out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with out_csv.open(\"w\", newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(result.keys())\n",
    "    with out_csv.open(\"r\", newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        existing_columns = next(reader)\n",
    "    if list(result.keys()) != existing_columns:\n",
    "        raise ValueError(f\"Columns mismatch: {list(result.keys())} != {existing_columns}\")\n",
    "    with out_csv.open(\"a\", newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(str(result[key]) for key in result.keys())\n",
    "\n",
    "\n",
    "def get_and_write_single_yes_no_result(\n",
    "        messages: list[dict],\n",
    "        model: str,\n",
    "        out_csv: Path,\n",
    "        tag: dict | None=None,\n",
    "        **model_kwargs\n",
    "    ):\n",
    "    tag = {} if tag is None else tag\n",
    "    datetime_str = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    text, token_logprobs = get_response_text_and_logprobs(messages, model, **model_kwargs)\n",
    "    yes_logprob, no_logprob = calculate_yes_no_logprobs(token_logprobs)\n",
    "    result = {\n",
    "        \"datetime\": datetime_str,\n",
    "        \"yes_logprob\": yes_logprob,\n",
    "        \"no_logprob\": no_logprob,\n",
    "        \"response_text\": text,\n",
    "        **{k: tag[k] for k in sorted(tag.keys())},\n",
    "        \"messages\": messages\n",
    "    }\n",
    "    append_to_csv(result, out_csv)\n",
    "\n",
    "\n",
    "def get_and_write_yes_no_results(\n",
    "        message_histories: list[list[dict]],\n",
    "        model: str,\n",
    "        out_csv: Path,\n",
    "        tags: list[dict] | None = None,\n",
    "        append_datetime_to_filename: bool = False,\n",
    "        **model_kwargs\n",
    "    ):\n",
    "    if not isinstance(out_csv, Path):\n",
    "        out_csv = Path(out_csv)\n",
    "    if append_datetime_to_filename:\n",
    "        datetime_str = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        out_csv = out_csv.with_name(f\"{out_csv.stem}_{datetime_str}{out_csv.suffix}\")\n",
    "    if out_csv.exists():\n",
    "        raise FileExistsError(f\"Output file {out_csv} already exists\")\n",
    "    if not isinstance(tags, list):\n",
    "        raise ValueError(\"tags must be a list of dictionaries\")\n",
    "\n",
    "    pbar = tqdm.tqdm(total=len(message_histories), desc=\"Processing elicitations\")\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = []\n",
    "        for messages, tag in zip(message_histories, tags):\n",
    "            future = executor.submit(\n",
    "                get_and_write_single_yes_no_result,\n",
    "                messages,\n",
    "                model,\n",
    "                out_csv,\n",
    "                tag,\n",
    "                **model_kwargs\n",
    "            )\n",
    "            futures.append(future)\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "\n",
    "def get_and_write_single_truth_lie_result(\n",
    "    messages: list[dict],\n",
    "    answer: str,\n",
    "    model: str,\n",
    "    out_csv: Path,\n",
    "    tag: dict | None = None,\n",
    "    **model_kwargs\n",
    "):\n",
    "    tag = {} if tag is None else tag\n",
    "    datetime_str = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    text, _ = get_response_text_and_logprobs(messages, model, **model_kwargs)\n",
    "    correct = answer.lower().strip() in text.lower()\n",
    "    result = {\n",
    "        \"datetime\": datetime_str,\n",
    "        \"answer\": answer,\n",
    "        \"correct\": correct,\n",
    "        \"response_text\": text,\n",
    "        **{k: tag[k] for k in sorted(tag.keys())},\n",
    "        \"messages\": messages\n",
    "    }\n",
    "    append_to_csv(result, out_csv)\n",
    "\n",
    "\n",
    "def get_and_write_truth_lie_results(\n",
    "    message_histories: list[list[dict]],\n",
    "    answers: list[str],\n",
    "    model: str,\n",
    "    out_csv: Path,\n",
    "    tags: list[dict] | None = None,\n",
    "    append_datetime_to_filename: bool = False,\n",
    "    **model_kwargs\n",
    "):\n",
    "    if not isinstance(out_csv, Path):\n",
    "        out_csv = Path(out_csv)\n",
    "    if append_datetime_to_filename:\n",
    "        datetime_str = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        out_csv = out_csv.with_name(f\"{out_csv.stem}_{datetime_str}{out_csv.suffix}\")\n",
    "    if out_csv.exists():\n",
    "        raise FileExistsError(f\"Output file {out_csv} already exists\")\n",
    "    if not isinstance(tags, list):\n",
    "        raise ValueError(\"tags must be a list of dictionaries\")\n",
    "    \n",
    "    pbar = tqdm.tqdm(total=len(message_histories), desc=\"Processing elicitations\")\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = []\n",
    "        for messages, answer, tag in zip(message_histories, answers, tags, strict=True):\n",
    "            future = executor.submit(\n",
    "                get_and_write_single_truth_lie_result,\n",
    "                messages,\n",
    "                answer,\n",
    "                model,\n",
    "                out_csv,\n",
    "                tag,\n",
    "                **model_kwargs\n",
    "            )\n",
    "            futures.append(future)\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            pbar.update(1)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing elicitations: 100%|██████████| 100/100 [00:05<00:00, 19.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "number_results = 100\n",
    "example_message_histories = [\n",
    "    create_single_message_history(\n",
    "        text=f\"You are assistant {i}. Answer no.\",\n",
    "    ) for i in range(number_results)\n",
    "]\n",
    "tag = [{\"example_tag1\": 1, \"example_tag2\": \"2\"} for _ in range(number_results)]\n",
    "\n",
    "get_and_write_yes_no_results(\n",
    "    message_histories=example_message_histories,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    out_csv=\"example_outputs/example_out.csv\",\n",
    "    tags=tag,\n",
    "    append_datetime_to_filename=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sciq recreation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from original_prompts.truth_lie_instructions import default_lie_instructions, default_truth_instructions\n",
    "\n",
    "probes_df = pd.read_csv(\"original_prompts/probes.csv\")\n",
    "sciq_df = pd.read_csv(\"original_prompts/sciq.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing elicitations: 100%|██████████| 13000/13000 [12:15<00:00, 17.67it/s]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "message_histories = []\n",
    "tags = []\n",
    "answers = []\n",
    "for sciq_row in sciq_df.itertuples():\n",
    "    truth_instruction = str(rng.choice(default_truth_instructions))\n",
    "    lie_instruction = str(rng.choice(default_lie_instructions))\n",
    "    for instructed_to_lie, instruction in [\n",
    "        (False, truth_instruction),\n",
    "        (True, lie_instruction),\n",
    "    ]:\n",
    "        prompt = f\"{instruction}\\n\\nQuestion:\\n{sciq_row.question}\\n\\nAnswer:\\n\"\n",
    "        messages = create_single_message_history(\n",
    "            text=prompt\n",
    "        )\n",
    "        message_histories.append(messages)\n",
    "        tags.append({\n",
    "            \"question\": sciq_row.question,\n",
    "            \"instructed_to_lie\": instructed_to_lie,\n",
    "            \"instruction\": instruction,\n",
    "        })\n",
    "        answers.append(sciq_row.answer)\n",
    "\n",
    "n = None\n",
    "if n is not None:\n",
    "    message_histories = message_histories[:n]\n",
    "    answers = answers[:n]\n",
    "    tags = tags[:n]\n",
    "get_and_write_truth_lie_results(\n",
    "    message_histories=message_histories,\n",
    "    answers=answers,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    out_csv=\"outputs/sciq_truth_lie_results.csv\",\n",
    "    tags=tags,\n",
    "    append_datetime_to_filename=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
