{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import openai\n",
    "import tqdm\n",
    "\n",
    "client = openai.OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_messages(context: str, elicitation_question: str):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": \"When requested to, only respond with 'Yes' or 'No'. Do not provide any other information or thoughts.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Context: {context}\\nElicitation Question: {elicitation_question}\"}\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_text_and_logprobs_from_response(response):\n",
    "    text = response.choices[0].message.content\n",
    "    token_logprobs = {\n",
    "        x.token: x.logprob for x in response.choices[0].logprobs.content[0].top_logprobs\n",
    "    }\n",
    "    return text, token_logprobs \n",
    "\n",
    "\n",
    "def get_response_text_and_logprobs(messages: list[dict], model: str, **model_kwargs):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        logprobs=model_kwargs.pop(\"logprobs\", True),\n",
    "        top_logprobs=model_kwargs.pop(\"top_logprobs\", 10),\n",
    "        **model_kwargs\n",
    "    )\n",
    "    text = response.choices[0].message.content\n",
    "    token_logprobs = {\n",
    "        x.token: x.logprob for x in response.choices[0].logprobs.content[0].top_logprobs\n",
    "    }\n",
    "    return text, token_logprobs\n",
    "\n",
    "\n",
    "def calculate_yes_no_logprobs(token_logprobs: dict[str, float]):\n",
    "    yes_logprob = 0\n",
    "    no_logprob = 0\n",
    "    for token, logprob in token_logprobs.items():\n",
    "        if token.lower() == \"yes\":\n",
    "            yes_logprob += logprob\n",
    "        elif token.lower() == \"no\":\n",
    "            no_logprob += logprob\n",
    "    return yes_logprob, no_logprob\n",
    "\n",
    "\n",
    "def get_and_write_single_elicitation_result(\n",
    "        context: str,\n",
    "        elicitation_question: str,\n",
    "        model: str,\n",
    "        out_csv: Path,\n",
    "        tags: dict | None=None,\n",
    "        **model_kwargs\n",
    "    ):\n",
    "    if not isinstance(out_csv, Path):\n",
    "        out_csv = Path(out_csv)\n",
    "    tags = {} if tags is None else tags\n",
    "\n",
    "    datetime_str = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    messages = create_messages(context, elicitation_question)\n",
    "    text, token_logprobs = get_response_text_and_logprobs(messages, model, **model_kwargs)\n",
    "    yes_logprob, no_logprob = calculate_yes_no_logprobs(token_logprobs)\n",
    "    result = {\n",
    "        \"datetime\": datetime_str,\n",
    "        \"yes_logprob\": yes_logprob,\n",
    "        \"no_logprob\": no_logprob,\n",
    "        \"context\": context,\n",
    "        \"elicitation_question\": elicitation_question,\n",
    "        \"text\": text,\n",
    "        **{k: tags[k] for k in sorted(tags.keys())}\n",
    "    }\n",
    "\n",
    "    if not out_csv.exists():\n",
    "        out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with out_csv.open(\"w\") as f:\n",
    "            f.write(f\"{','.join(result.keys())}\\n\")\n",
    "    existing_columns = out_csv.read_text().split(\"\\n\")[0].split(\",\")\n",
    "    if list(result.keys()) != existing_columns:\n",
    "        raise ValueError(f\"Columns mismatch: {list(result.keys())} != {existing_columns}\")\n",
    "    with out_csv.open(\"a\") as f:\n",
    "        f.write(f\"{','.join(str(result[key]) for key in result.keys())}\\n\")\n",
    "\n",
    "\n",
    "def get_and_write_elicitation_results(\n",
    "        contexts: list[str],\n",
    "        elicitation_questions: list[str],\n",
    "        model: str,\n",
    "        out_csv: Path,\n",
    "        tags: list[dict] | None = None,\n",
    "        append_datetime_to_filename: bool = False,\n",
    "        **model_kwargs\n",
    "    ):\n",
    "    if not isinstance(out_csv, Path):\n",
    "        out_csv = Path(out_csv)\n",
    "    if append_datetime_to_filename:\n",
    "        datetime_str = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        out_csv = out_csv.with_name(f\"{out_csv.stem}_{datetime_str}{out_csv.suffix}\")\n",
    "    if out_csv.exists():\n",
    "        raise FileExistsError(f\"Output file {out_csv} already exists\")\n",
    "    if not isinstance(tags, list):\n",
    "        raise ValueError(\"tags must be a list of dictionaries\")\n",
    "\n",
    "    pbar = tqdm.tqdm(total=len(contexts), desc=\"Processing elicitations\")\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = []\n",
    "        for context, elicitation_question, tag in zip(contexts, elicitation_questions, tags):\n",
    "            future = executor.submit(\n",
    "                get_and_write_single_elicitation_result,\n",
    "                context,\n",
    "                elicitation_question, \n",
    "                model,\n",
    "                out_csv,\n",
    "                tag,\n",
    "                **model_kwargs\n",
    "            )\n",
    "            futures.append(future)\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            pbar.update(1)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing elicitations: 100%|██████████| 10/10 [00:01<00:00,  8.10it/s]\n"
     ]
    }
   ],
   "source": [
    "number_results = 10\n",
    "example_contexts = [f\"Example context {i}\" for i in range(number_results)]\n",
    "elicitation_questions = [f\"Question {i}: Answer randomly: Yes or No\" for i in range(number_results)]\n",
    "tags = [{\"example_tag1\": 1, \"example_tag2\": \"2\"} for _ in range(number_results)]\n",
    "\n",
    "get_and_write_elicitation_results(\n",
    "    contexts=example_contexts,\n",
    "    elicitation_questions=elicitation_questions,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    out_csv=f\"example_outputs/example_out_{number_results}.csv\",\n",
    "    tags=tags,\n",
    "    append_datetime_to_filename=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
